"""FunctionCallAgent - ä½¿ç”¨OpenAIå‡½æ•°è°ƒç”¨èŒƒå¼çš„Agentå®ç°"""

from __future__ import annotations

import json
from typing import Iterator, Optional, Union, TYPE_CHECKING, Any, Dict

from ..core.agent import Agent
from ..core.config import Config
from ..core.llm import HelloAgentsLLM
from ..core.message import Message

if TYPE_CHECKING:
    from ..tools.registry import ToolRegistry


def _map_parameter_type(param_type: str) -> str:
    """å°†å·¥å…·å‚æ•°ç±»å‹æ˜ å°„ä¸ºJSON Schemaå…è®¸çš„ç±»å‹"""
    normalized = (param_type or "").lower()
    if normalized in {"string", "number", "integer", "boolean", "array", "object"}:
        return normalized
    return "string"


class FunctionCallAgent(Agent):
    """åŸºäºOpenAIåŸç”Ÿå‡½æ•°è°ƒç”¨æœºåˆ¶çš„Agent"""

    def __init__(
        self,
        name: str,
        llm: HelloAgentsLLM,
        system_prompt: Optional[str] = None,
        config: Optional[Config] = None,
        tool_registry: Optional["ToolRegistry"] = None,
        enable_tool_calling: bool = True,
        default_tool_choice: Union[str, dict] = "auto",
        max_tool_iterations: int = 3,
    ):
        super().__init__(name, llm, system_prompt, config)
        self.tool_registry = tool_registry
        self.enable_tool_calling = enable_tool_calling and tool_registry is not None
        self.default_tool_choice = default_tool_choice
        self.max_tool_iterations = max_tool_iterations

    def _get_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼Œæ³¨å…¥å·¥å…·æè¿°"""
        base_prompt = self.system_prompt or "ä½ æ˜¯ä¸€ä¸ªå¯é çš„AIåŠ©ç†ï¼Œèƒ½å¤Ÿåœ¨éœ€è¦æ—¶è°ƒç”¨å·¥å…·å®Œæˆä»»åŠ¡ã€‚"

        if not self.enable_tool_calling or not self.tool_registry:
            return base_prompt

        tools_description = self.tool_registry.get_tools_description()
        if not tools_description or tools_description == "æš‚æ— å¯ç”¨å·¥å…·":
            return base_prompt

        prompt = base_prompt + "\n\n## å¯ç”¨å·¥å…·\n"
        prompt += "å½“ä½ åˆ¤æ–­éœ€è¦å¤–éƒ¨ä¿¡æ¯æˆ–æ‰§è¡ŒåŠ¨ä½œæ—¶ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡å‡½æ•°è°ƒç”¨ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š\n"
        prompt += tools_description + "\n"
        prompt += "\nè¯·ä¸»åŠ¨å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ï¼Œåˆç†åˆ©ç”¨å¤šæ¬¡è°ƒç”¨æ¥è·å¾—å®Œå¤‡ç­”æ¡ˆã€‚"
        return prompt

    def _build_tool_schemas(self) -> list[dict[str, Any]]:
        if not self.enable_tool_calling or not self.tool_registry:
            return []

        schemas: list[dict[str, Any]] = []

        # Toolå¯¹è±¡
        for tool in self.tool_registry.get_all_tools():
            properties: Dict[str, Any] = {}
            required: list[str] = []

            try:
                parameters = tool.get_parameters()
            except Exception:
                parameters = []

            for param in parameters:
                properties[param.name] = {
                    "type": _map_parameter_type(param.type),
                    "description": param.description or ""
                }
                if param.default is not None:
                    properties[param.name]["default"] = param.default
                if getattr(param, "required", True):
                    required.append(param.name)

            schema: dict[str, Any] = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description or "",
                    "parameters": {
                        "type": "object",
                        "properties": properties
                    }
                }
            }
            if required:
                schema["function"]["parameters"]["required"] = required
            schemas.append(schema)

        # register_function æ³¨å†Œçš„å·¥å…·ï¼ˆç›´æ¥è®¿é—®å†…éƒ¨ç»“æ„ï¼‰
        function_map = getattr(self.tool_registry, "_functions", {})
        for name, info in function_map.items():
            schemas.append(
                {
                    "type": "function",
                    "function": {
                        "name": name,
                        "description": info.get("description", ""),
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "input": {
                                    "type": "string",
                                    "description": "è¾“å…¥æ–‡æœ¬"
                                }
                            },
                            "required": ["input"]
                        }
                    }
                }
            )

        return schemas

    @staticmethod
    def _extract_message_content(raw_content: Any) -> str:
        """ä»OpenAIå“åº”çš„message.contentä¸­å®‰å…¨æå–æ–‡æœ¬"""
        if raw_content is None:
            return ""
        if isinstance(raw_content, str):
            return raw_content
        if isinstance(raw_content, list):
            parts: list[str] = []
            for item in raw_content:
                text = getattr(item, "text", None)
                if text is None and isinstance(item, dict):
                    text = item.get("text")
                if text:
                    parts.append(text)
            return "".join(parts)
        return str(raw_content)

    @staticmethod
    def _parse_function_call_arguments(arguments: Optional[str]) -> dict[str, Any]:
        """è§£ææ¨¡å‹è¿”å›çš„JSONå­—ç¬¦ä¸²å‚æ•°"""
        if not arguments:
            return {}

        try:
            parsed = json.loads(arguments)
            return parsed if isinstance(parsed, dict) else {}
        except json.JSONDecodeError:
            return {}

    def _convert_parameter_types(self, tool_name: str, param_dict: dict[str, Any]) -> dict[str, Any]:
        """æ ¹æ®å·¥å…·å®šä¹‰å°½å¯èƒ½è½¬æ¢å‚æ•°ç±»å‹"""
        if not self.tool_registry:
            return param_dict

        tool = self.tool_registry.get_tool(tool_name)
        if not tool:
            return param_dict

        try:
            tool_params = tool.get_parameters()
        except Exception:
            return param_dict

        type_mapping = {param.name: param.type for param in tool_params}
        converted: dict[str, Any] = {}

        for key, value in param_dict.items():
            param_type = type_mapping.get(key)
            if not param_type:
                converted[key] = value
                continue

            try:
                normalized = param_type.lower()
                if normalized in {"number", "float"}:
                    converted[key] = float(value)
                elif normalized in {"integer", "int"}:
                    converted[key] = int(value)
                elif normalized in {"boolean", "bool"}:
                    if isinstance(value, bool):
                        converted[key] = value
                    elif isinstance(value, (int, float)):
                        converted[key] = bool(value)
                    elif isinstance(value, str):
                        converted[key] = value.lower() in {"true", "1", "yes"}
                    else:
                        converted[key] = bool(value)
                else:
                    converted[key] = value
            except (TypeError, ValueError):
                converted[key] = value

        return converted

    def _execute_tool_call(self, tool_name: str, arguments: dict[str, Any]) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è¿”å›å­—ç¬¦ä¸²ç»“æœ"""
        if not self.tool_registry:
            return "âŒ é”™è¯¯ï¼šæœªé…ç½®å·¥å…·æ³¨å†Œè¡¨"

        tool = self.tool_registry.get_tool(tool_name)
        if tool:
            try:
                typed_arguments = self._convert_parameter_types(tool_name, arguments)
                return tool.run(typed_arguments)
            except Exception as exc:
                return f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥ï¼š{exc}"

        func = self.tool_registry.get_function(tool_name)
        if func:
            try:
                input_text = arguments.get("input", "")
                return func(input_text)
            except Exception as exc:
                return f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥ï¼š{exc}"

        return f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°å·¥å…· '{tool_name}'"

    def _invoke_with_tools(self, messages: list[dict[str, Any]], tools: list[dict[str, Any]], tool_choice: Union[str, dict], **kwargs):
        """è°ƒç”¨åº•å±‚OpenAIå®¢æˆ·ç«¯æ‰§è¡Œå‡½æ•°è°ƒç”¨"""
        client = getattr(self.llm, "_client", None)
        if client is None:
            raise RuntimeError("HelloAgentsLLM æœªæ­£ç¡®åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ— æ³•æ‰§è¡Œå‡½æ•°è°ƒç”¨ã€‚")

        client_kwargs = dict(kwargs)
        client_kwargs.setdefault("temperature", self.llm.temperature)
        if self.llm.max_tokens is not None:
            client_kwargs.setdefault("max_tokens", self.llm.max_tokens)

        return client.chat.completions.create(
            model=self.llm.model,
            messages=messages,
            tools=tools,
            tool_choice=tool_choice,
            **client_kwargs,
        )

    def run(
        self,
        input_text: str,
        *,
        max_tool_iterations: Optional[int] = None,
        tool_choice: Optional[Union[str, dict]] = None,
        **kwargs,
    ) -> str:
        """
        æ‰§è¡Œå‡½æ•°è°ƒç”¨èŒƒå¼çš„å¯¹è¯æµç¨‹
        """
        messages: list[dict[str, Any]] = []
        system_prompt = self._get_system_prompt()
        messages.append({"role": "system", "content": system_prompt})

        for msg in self._history:
            messages.append({"role": msg.role, "content": msg.content})

        messages.append({"role": "user", "content": input_text})

        tool_schemas = self._build_tool_schemas()
        if not tool_schemas:
            response_text = self.llm.invoke(messages, **kwargs)
            self.add_message(Message(input_text, "user"))
            self.add_message(Message(response_text, "assistant"))
            return response_text

        iterations_limit = max_tool_iterations if max_tool_iterations is not None else self.max_tool_iterations
        effective_tool_choice: Union[str, dict] = tool_choice if tool_choice is not None else self.default_tool_choice

        current_iteration = 0
        final_response = ""

        while current_iteration < iterations_limit:
            response = self._invoke_with_tools(
                messages,
                tools=tool_schemas,
                tool_choice=effective_tool_choice,
                **kwargs,
            )

            choice = response.choices[0]
            assistant_message = choice.message
            content = self._extract_message_content(assistant_message.content)
            tool_calls = list(assistant_message.tool_calls or [])

            if tool_calls:
                assistant_payload: dict[str, Any] = {"role": "assistant", "content": content}
                assistant_payload["tool_calls"] = []

                for tool_call in tool_calls:
                    assistant_payload["tool_calls"].append(
                        {
                            "id": tool_call.id,
                            "type": tool_call.type,
                            "function": {
                                "name": tool_call.function.name,
                                "arguments": tool_call.function.arguments,
                            },
                        }
                    )
                messages.append(assistant_payload)

                for tool_call in tool_calls:
                    tool_name = tool_call.function.name
                    arguments = self._parse_function_call_arguments(tool_call.function.arguments)
                    result = self._execute_tool_call(tool_name, arguments)
                    messages.append(
                        {
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "name": tool_name,
                            "content": result,
                        }
                    )

                current_iteration += 1
                continue

            final_response = content
            messages.append({"role": "assistant", "content": final_response})
            break

        if current_iteration >= iterations_limit and not final_response:
            final_choice = self._invoke_with_tools(
                messages,
                tools=tool_schemas,
                tool_choice="none",
                **kwargs,
            )
            final_response = self._extract_message_content(final_choice.choices[0].message.content)
            messages.append({"role": "assistant", "content": final_response})

        self.add_message(Message(input_text, "user"))
        self.add_message(Message(final_response, "assistant"))
        return final_response

    def add_tool(self, tool) -> None:
        """ä¾¿æ·æ–¹æ³•ï¼šå°†å·¥å…·æ³¨å†Œåˆ°å½“å‰Agent"""
        if not self.tool_registry:
            from ..tools.registry import ToolRegistry

            self.tool_registry = ToolRegistry()
            self.enable_tool_calling = True

        if hasattr(tool, "auto_expand") and getattr(tool, "auto_expand"):
            expanded_tools = tool.get_expanded_tools()
            if expanded_tools:
                for expanded_tool in expanded_tools:
                    self.tool_registry.register_tool(expanded_tool)
                print(f"âœ… MCPå·¥å…· '{tool.name}' å·²å±•å¼€ä¸º {len(expanded_tools)} ä¸ªç‹¬ç«‹å·¥å…·")
                return

        self.tool_registry.register_tool(tool)

    def remove_tool(self, tool_name: str) -> bool:
        if self.tool_registry:
            before = set(self.tool_registry.list_tools())
            self.tool_registry.unregister(tool_name)
            after = set(self.tool_registry.list_tools())
            return tool_name in before and tool_name not in after
        return False

    def list_tools(self) -> list[str]:
        if self.tool_registry:
            return self.tool_registry.list_tools()
        return []

    def has_tools(self) -> bool:
        return self.enable_tool_calling and self.tool_registry is not None

    def stream_run(self, input_text: str, **kwargs) -> Iterator[str]:
        """æµå¼è°ƒç”¨ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨çš„å®Œæ•´å¯è§‚æµ‹æ€§
        
        é‡è¦é™åˆ¶ï¼šfunction callingèŒƒå¼çš„å›ºæœ‰é™åˆ¶
        - æ— æ³•å®ç°çœŸæ­£çš„ç«¯åˆ°ç«¯æµå¼è¾“å‡ºï¼ˆstream-and-callï¼‰
        - å¿…é¡»å…ˆæ‰§è¡Œå®Œæ•´çš„å·¥å…·è°ƒç”¨æµç¨‹ï¼Œç„¶åæ‰èƒ½æµå¼è¾“å‡ºæœ€ç»ˆå“åº”
        
        æ‰€ä»¥æœ€ç»ˆå“åº”æ˜¯éæµå¼è·å¾—çš„ï¼ˆå·²ç»ä»æ¨¡å‹è¾“å‡ºï¼‰ã€‚
        æˆ‘ä»¬å¸®ä½ æä¾›äº†ä¸¤ç§æ–¹å¼ï¼š
        1. ç›´æ¥è¾“å‡ºå·²æœ‰çš„å“åº”ï¼ˆå½“å‰ï¼‰ï¼šå®æ—¶ä½†ä¸æ˜¯çœŸæ­£æµå¼
        2. é‡æ–°ç”¨æµå¼æ¥å£ï¼ˆå¯é€‰ï¼‰ï¼šçœŸæ­£æµå¼ä½†æ˜¯æ–°ç”Ÿæˆ
        """
        messages: list[dict[str, Any]] = []
        system_prompt = self._get_system_prompt()
        messages.append({"role": "system", "content": system_prompt})

        for msg in self._history:
            messages.append({"role": msg.role, "content": msg.content})

        messages.append({"role": "user", "content": input_text})

        tool_schemas = self._build_tool_schemas()
        
        # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œç›´æ¥æµå¼è¾“å‡º
        if not tool_schemas:
            full_response = ""
            for chunk in self.llm.stream_invoke(messages, **kwargs):
                full_response += chunk
                yield chunk
            self.add_message(Message(input_text, "user"))
            self.add_message(Message(full_response, "assistant"))
            return
        
        # å¦‚æœæœ‰å·¥å…·ï¼Œæ‰§è¡Œå®Œæ•´çš„å·¥å…·è°ƒç”¨æµç¨‹
        iterations_limit = kwargs.get('max_tool_iterations', self.max_tool_iterations)
        effective_tool_choice = kwargs.get('tool_choice', self.default_tool_choice)
        
        current_iteration = 0
        final_response = ""
        
        while current_iteration < iterations_limit:
            response = self._invoke_with_tools(
                messages,
                tools=tool_schemas,
                tool_choice=effective_tool_choice,
                **{k: v for k, v in kwargs.items() if k not in ['max_tool_iterations', 'tool_choice']}
            )
            
            choice = response.choices[0]
            assistant_message = choice.message
            content = self._extract_message_content(assistant_message.content)
            tool_calls = list(assistant_message.tool_calls or [])
            
            if tool_calls:
                # æœ‰å·¥å…·è°ƒç”¨ï¼Œå…ˆæ·»åŠ assistantæ¶ˆæ¯ï¼ˆåŒ…å«tool_callsï¼‰
                assistant_payload: dict[str, Any] = {"role": "assistant", "content": content}
                assistant_payload["tool_calls"] = []
                
                for tool_call in tool_calls:
                    tool_name = tool_call.function.name
                    arguments = self._parse_function_call_arguments(tool_call.function.arguments)
                    
                    assistant_payload["tool_calls"].append(
                        {
                            "id": tool_call.id,
                            "type": tool_call.type,
                            "function": {
                                "name": tool_call.function.name,
                                "arguments": tool_call.function.arguments,
                            },
                        }
                    )
                
                # å…ˆæ·»åŠ assistantæ¶ˆæ¯åˆ°æ¶ˆæ¯å†å²
                messages.append(assistant_payload)
                
                # ç„¶åæ‰§è¡Œå·¥å…·å¹¶è¾“å‡ºç»“æœ
                for tool_call in tool_calls:
                    tool_name = tool_call.function.name
                    arguments = self._parse_function_call_arguments(tool_call.function.arguments)
                    
                    # è¾“å‡ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                    yield f"\nğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}\n"
                    yield f"ğŸ“¥ å‚æ•°: {tool_call.function.arguments}\n"
                    
                    # æ‰§è¡Œå·¥å…·
                    result = self._execute_tool_call(tool_name, arguments)
                    yield f"ğŸ“¤ ç»“æœ: {result}\n"
                    
                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
                    messages.append(
                        {
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "name": tool_name,
                            "content": result,
                        }
                    )
                
                current_iteration += 1
                continue
            
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè·å–æœ€ç»ˆå“åº”
            final_response = content
            messages.append({"role": "assistant", "content": final_response})
            break
        
        # å¦‚æœè¾¾åˆ°è¿­ä»£é™åˆ¶ä½†æ²¡æœ‰æœ€ç»ˆå“åº”ï¼Œå¼ºåˆ¶è·å–æœ€ç»ˆå“åº”ï¼ˆæµå¼ï¼‰
        if current_iteration >= iterations_limit and not final_response:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œè®¾ç½® tool_choice="none" é˜²æ­¢æ¨¡å‹ç»§ç»­è°ƒç”¨å·¥å…·
            final_messages = messages.copy()
            final_messages.append({
                "role": "assistant",
                "content": "æˆ‘å·²è¾¾åˆ°å·¥å…·è°ƒç”¨é™åˆ¶ï¼Œç°åœ¨ç›´æ¥æä¾›ç­”æ¡ˆã€‚"
            })
            
            # ä½¿ç”¨æµå¼æ¥å£è·å–æœ€ç»ˆå“åº”
            final_response = ""
            for chunk in self.llm.stream_invoke(final_messages, **{k: v for k, v in kwargs.items() if k not in ['max_tool_iterations', 'tool_choice']}):
                final_response += chunk
                yield chunk
            messages.append({"role": "assistant", "content": final_response})
        
        # ä¿å­˜å¯¹è¯å†å²
        self.add_message(Message(input_text, "user"))
        self.add_message(Message(final_response, "assistant"))

